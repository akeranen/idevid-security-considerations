---
title: Security and Operational considerations for manufacturer installed keys and anchors
abbrev: IDevID Considerations
docname: draft-richardson-secdispatch-idevid-considerations-01

ipr: trust200902
area: Internet
wg: anima Working Group
kw: Internet-Draft
cat: std

pi:
  toc: yes
  symrefs: yes

author:


- ins: M. Richardson
  name: Michael Richardson
  org: Sandelman Software Works
  email: mcr+ietf@sandelman.ca

- ins: W. Pan
  name: Wei Pan
  org: Huawei Technologies
  email: william.panwei@huawei.com


normative:
  BCP14: RFC8174
  I-D.moskowitz-ecdsa-pki:
  ieee802-1AR:
    target: "http://standards.ieee.org/findstds/standard/802.1AR-2009.html"
    title: "IEEE 802.1AR Secure Device Identifier"
    author:
      ins: "IEEE Standard"
    date: 2009

informative:
  I-D.richardson-anima-masa-considerations:
  I-D.ietf-anima-bootstrapping-keyinfra: BRSKI
  RFC8366:
  BedOfNails:
    title: "In-circuit test"
    author:
      org: "Wikipedia"
    target: "https://en.wikipedia.org/wiki/In-circuit_test#Bed_of_nails_tester"
    date: 2019

  pelionfcu:
    title: "Factory provisioning overview"
    target:  https://www.pelion.com/docs/device-management-provision/1.2/introduction/index.html
    author:
      org: "ARM Pelion"
    date: 2020-06-28

  factoringrsa:
    title: "Factoring RSA keys from certified smart cards: Coppersmith in the wild"
    target: https://core.ac.uk/download/pdf/204886987.pdf
    date: 2013-09-16

  RambusCryptoManager:
    title: "Qualcomm Licenses Rambus CryptoManager Key and Feature Management Security Solution"
    target: "https://www.rambus.com/qualcomm-licenses-rambus-cryptomanager-key-and-feature-management-security-solution/"
    author:
      org: "Qualcomm press release"
    date: 2014

  kskceremony:
    title: "DNSSEC Practice Statement for the Root Zone ZSK Operator"
    target: "https://www.iana.org/dnssec/dps/zsk-operator/dps-zsk-operator-v2.0.pdf"
    author:
      org: "Verisign"
    date: 2017

  rootkeyceremony:
     title: "Root Key Ceremony, Cryptography Wiki"
     target: "https://cryptography.fandom.com/wiki/Root_Key_Ceremony"
     author:
       org: "Community"
     date: "2020-04-04"

  keyceremony2:
     title: "SAS 70 Key Ceremony"
     target: "http://www.digi-sign.com/compliance/key%20ceremony/index"
     author:
       org: "Digi-Sign"
     date: "2020-04-04"

  nistsp800-57:
    title: "SP 800-57 Part 1 Rev. 4 Recommendation for Key Management, Part 1: General"
    target: "https://csrc.nist.gov/publications/detail/sp/800-57-part-1/rev-4/final"
    author:
      org: "NIST"
    date: 2016-01-01

  fidotechnote:
    target: "https://fidoalliance.org/fido-technotes-the-truth-about-attestation/"
    title: "FIDO TechNotes: The Truth about Attestation"
    author:
      ins: "FIDO Alliance"
      date: "2018-07-19"

  ntiasbom:
    target: "https://www.it-cisq.org/software-bill-of-materials/index.htm"
    title: "TOOL-TO-TOOL SOFTWARE BILL OF MATERIALS EXCHANGE"
    author:
      ins: "CISQ/Object Management Group"
      date: "2020-07-01"

  openbmc:
    target: "https://www.openbmc.org/"
    title: "Defining a Standard Baseboard Management Controller Firmware Stack"
    author:
      ins: "Linux Foundation/OpenBMC Group"
      date: "2020-07-01"

  JTAG:
    target: "https://ieeexplore.ieee.org/document/5412866"
    title: "
1149.7-2009 - IEEE Standard for Reduced-Pin and Enhanced-Functionality Test Access Port and Boundary-Scan Architecture"
    author:
      ins: "IEEE Standard"
    date: 2009
    doi: 10.1109/IEEESTD.2010.5412866

  BedOfNails:
    target: "https://en.wikipedia.org/wiki/In-circuit_test#Bed_of_nails_tester"
    title: "Bed of nails tester"
    author:
      ins: "Wikipedia"
      date: "2020-07-01"



--- abstract

This document provides a nomenclature to describe ways in which manufacturers
secure private keys and public trust anchors in devices.

--- middle

# Introduction

An increasing number of protocols derive a significant part of their security by using trust anchors that are installed by manufacturers.
Access to these trust anchors does not usually cause a problem, but changing them in any way does.
This includes adding, replacing or deleting anchors.

Additionally, many protocols leverage manufacturer installed identities.
These identities are usually in the form of {{ieee802-1AR}} Initial Device Identity certificates (IDevID).
The identity has two components: a private key that must remain under the strict control of a trusted part of the device, and a public part (the certificate), which (ignoring, for the moment, personal privacy concerns) may be freely disclosed.

It is further not unusual for many devices (particularly smartphones) to also have one or more group identity keys.
This is used in, for instance, in {{fidotechnote}} to make claims about being a particular model of phone (see {{?I-D.richardson-rats-usecases}}).
The keypair that does this is loaded into large batches of phones for privacy reasons.

The trust anchors are used for a variety of purposes.
The following uses are specifically called out:

* to validate the signature on a software update (as per {{?I-D.ietf-suit-architecture}}).
* to verify the end of a TLS Server Certificate, such as when setting up an HTTPS connection.
* to verify the {{RFC8366}} format voucher that provides proof of an ownership change

Device identity keys are used when performing enrollment requests (in {{?I-D.ietf-anima-bootstrapping-keyinfra}}, and in some uses of {{?I-D.ietf-emu-eap-noob}}.
The device identity certificate is also used to sign Evidence by an Attesting Environment (see {{?I-D.ietf-rats-architecture}}).

These security artifacts are used to anchor other chains of information: an EAT Claim as to the version of software/firmware running on a device (XXX and {{?I-D.birkholz-suit-coswid-manifest}}),
an EAT claim about legitimate network activity (via {{?I-D.birkholz-rats-mud}}, or embedded in the IDevID
in {{?RFC8520}}).
Known software versions lead directly to vendor/distributor signed Software Bill of Materials (SBOM),
such as those described by {{?I-D.ietf-sacm-coswid}} and the NTIA/CISQ/OMG SBOM work underway {{ntiasbom}}.

In order to manage risks and assess vulnerabilities in a Supply Chain, it is necessary to determine a degree of trusthworthiness in each device.
A device may mislead audit systems as to its provenance, about its software load or even about what kind of device it is. (see {{?RFC7168}} for a humourous example).
In order to properly assess he security of a Supply Chain it is necessary to understand the kinds and severity of the threats which a device has been designed to resist.
To do this, it is necessary to understand the ways in which the different trust anchors and identities are initially provisioned, are protected, and are updated.

To do this, this document details the different trust anchors (TrA) and identities (IDs) found in typical devices.
The privacy and integrity of the TAs and IDs is often provided by a different, superior artifacts.
This relationship is examined.

While many might desire to assign numerical values to different mitigation techniques in order to be able to rank them,  this document does not attempt to do, as there are too many other (mostly human) factors that would come into play.
Such an effort is more properly in the purvue of a formal ISO9001 process such as ISO14001.

## Terminology

This document is not a standards track document, and it does not make use of formal requirements language.

This section will be expanded to include needed terminology as required.

The words Trust Anchor are contracted to TrA rather than TA, in order not to confuse with {{I-D.ietf-teep-architecture}}'s "Trusted Application".

# Applicability Model

There is a wide variety of devices to which this analysis can apply. (See {{?I-D.bormann-lwig-7228bis}})
This document will use a J-group class C13 as a sample.
This class is sufficiently large to experience complex issues among multiple CPUs, packages and operating systems, but at the same time, small enough that this class is often deployed in single-purpose IoT-like uses.
Devices in this class often have Secure Enclaves (such as the "Grapeboard"), and can include silicon manufacturer controlled processors in the boot process (the Raspberry PI boots under control of the GPU).

Almost all larger systems (servers, laptops, desktops) include a Baseboard Management Controller (BMC), which ranges from a M-Group Class 3 MCU, to a J-Group Class 10 CPU (see, for instance {{openbmc}} which uses a Linux kernel and system inside the BMC).
As the BMC usually has complete access to the main CPU's memory, I/O hardware and disk, the boot path security of such a system needs to be understood first as being about the security of the BMC.

## A reference manufacturing/boot process

In order to provide for immutability and privacy of the critical TANs and IDs, many CPU manufacturers will provide for some kind of private memory area which is only accessible when the CPU is in certain priviledged states.
See the Terminology section of {{I-D.ietf-teep-architecture}}, notably TEE, REE, and TAM, and also section 4, Architecture.

The private memory that is important is usually non-volatile and rather small.
It may be located inside the CPU silicon die, or it may be located externally.
If the memory is external, then it is usually encrypted by a hardware mechanism on the CPU, with only the key kept inside the CPU.

This entire mechanism may be external to the CPU in the form of a hardware-TPM module, or it may be entirely internal to the CPU in the form of a firmware-TPM.
It may use a custom interface to the rest of the system, or it may implement the TPM 1.2 or TPM 2.0 specifications.
Those details are important to performing a proper evaluation, but do not matter that to this model.

During the manufacturing process, once the components have been soldered to the board, the system is usually put through a system-level test.
This is often done on as a "bed-of-nails" test {{BedOfNails}}, where the board has key points attached mechanically to a test system.
A {{JTAG}} process tests the System Under Test, and then initializes some firmware into the still empty flash storage.
It is now common for a factory test image to be loaded first: this image will include code to initialize the private memory key described above, and will include a first-stage bootloader and some kind of primitive Trusted Application Manager (TAM).
Embedded in the stage one bootloader will be a TrA that is able to verify the second-stage bootloader image.

After the system has undergone testing, the factory test image is erased, leaving the first-stage bootloader.
One or more second-stage bootloader images is installed.
The production image may be installed at that time, or if the second-stage bootloader is able to install it over the network, it may be done that way instead.

There are many variations of the above process.
There process may be entirely automated, or it may be entirely driven by humans working in the factory.
Or a combination of the above.
These steps may all occur on an access-controlled assembly line, or the system boards may be shipped from one place to another (maybe another country) before undergoing testing.

Some systems are intended to be shipped in a tamper-proof state, but it is usually not desireable that bed-of-nails testing be possible without tampering, so the initialization process is usually done prior to rendering the system tamper-proof.

Quality control testing may be done prior to as well as after the application of tamper-proofing, as systems which do not pass inspection may be reworked to fix flaws, and this should ideally be impossible once the system has been made tamper-proof.

# Types of Trust Anchors

## Types of identities



# Manufacturer installed IDevID certificates

{{I-D.ietf-anima-bootstrapping-keyinfra}} introduces a mechanism for
new devices (called pledges) to be onboarded into a network without
intervention from an expert operator.

This mechanism leverages the pre-existing relationship between a device and
the manufacturer that built the device.  There are two aspects to this
relationship: the provision of an identity for the device by the
manufacturer (the IDevID), and a mechanism which convinces the device to
trust the new owner (the {{RFC8366}} voucher).

This document is about the first part: where the device becomes trusted by
a network operator through a manufacturer provided trust anchor.
A second document, {{I-D.richardson-anima-masa-considerations}} deals with the
trust anchors needed to establish the device to operator trust relationship.

The operator to device trust relationship is in the form of an {{ieee802-1AR}}
certificate that is installed at manufacturing time in the device.

# Operational Considerations for Manufacturer IDevID Public Key Infrastructure

The manufacturer has the responsability to provision a keypair into each
device as part of the manufacturing process.  There are a variety of
mechanisms to accomplish this, which this document will overview.

There are three fundamental ways to generate IDevID certificates for devices:

1) generating a private key on the device, creating a Certificate Signing
Request (or equivalent), and then returning a certificate to the device.

2) generating a private key outside the device, signing the certificate, and
the installing both into the device.

3) deriving the private key from a previously installed secret seed, that is shared with only the manufacturer

There is a fourth situation where the IDevID is provided as part of a Trusted
Platform Module (TPM), in which case the TPM vendor may be making the same
tradeoffs.  Or the mechanisms to install the certificate into the TPM will
use TPM APIs.

The document {{I-D.moskowitz-ecdsa-pki}} provides some practical instructions
on setting up a reference implementation for ECDSA keys using a three-tier
mechanism.  This document recommends the use of ECDSA keys for the root
and intermediate CAs, but there may be operational reasons why an RSA intermediate
CA will be required for some legacy TPM equipment.

## Key Generation process

### On-device private key generation

Generating the key on-device has the advantage that the private key never
leaves the device.
The disadvantage is that the device may not have a verified random number generator.

There are a number of options of how to get the public key securely from the
device to the certification authority.
This transmission must be done in an integral manner, and must be securely associated with the assigned serial number.
The serial number goes into the certificate, and the resulting certificate needs to be loaded into the manufacturer's asset database.
This asset database needs to be shared with the MASA.

One way to do the transmission is during a manufacturing during a Bed of Nails (see {{BedOfNails}}) or Boundary Scan.
There are other ways that could be used where a certificate signing request is sent over a special network channel when the device is powered up in the factory.
After the key generation, the device needs to set a flag such that it no longer generates a new key, or will accept a new IDevID via the factory connection.
This may be a software setting, or could be as dramatic as blowing a fuse.

There may be risks with this method if an attacker with physical access is able to put the device back into an unconfigured mode, particularly if this may permit the attacker to get access to the private key material.
When done on a single device, such an attack may be able to replace the IDevID with one signed by another manufacturer.
That does not result in a risk of counterfeit devices.
An attack that is able to extract the private key could clone the device.

### Off-device private key generation

Generating the key off-device has the advantage that the randomness of the
private key can be better analyzed.
As the private key is available to the manufacturing infrastructure, the authenticity of the public key is well known ahead of time.
If the device does not come with a serial number in silicon, then one should be be assigned and placed into a certificate.
The private key and certificate could be programmed into the device along with the initial bootloader firmware in a single step.

The major downside to generating the private key off-device is that it could be seen by the manufacturing infrastructure.
This makes the manufacturing infrastructure a high-value attack target, so a mechanism is needed to keep the private key secure within the manufacturing process.

Encrypting the private key would solve this, but then the symmetric key would
need to be shared with the device, which is back to the original problem.

If keys are generated by the manufacturing plant, and are immediately installed, but never stored, then the window in which an attacker can gain access to the private key is immensely reduced.

### Key setup based on 256-bit secret seed

A hybrid of the previous two methods leverages a symmetric key that is often provided by a silicon vendor to OEM manufacturers.
Each CPU (or a Trusted Execution Environment {{?I-D.ietf-teep-architecture}}, or a TPM) is provisioned at fabrication time with a unique, secret seed, usually at least 256-bits in size.

This value is revealed to the OEM board manufacturer only via a secure channel.
Upon first boot, the system (probably within a TEE, or within a TPM) will generate a key pair using the seed to initialize a Pseudo-Random-Number-Generator (PRNG).
The OEM, in a separate system, will initialize the same PRNG and generate the same key pair.
The OEM then derives the public key part, signs it and turns it into a certificate.
The private part is then destroyed, ideally never stored or seen by anyone.
The certificate (being public information) is placed into a database, in some cases it is loaded by the device as its IDevID certificate, in other cases, it is retrieved during the onboarding process based upon a unique serial number asserted by the device.

This method appears to have all of the downsides of the previous two methods: the device must correctly derive its own private key, and the OEM has access to the private key, making it also vulnerable.
The secret seed must be created in a secure way and it must also be communicated securely.

There are some advantages to the OEM however: the major one is that the problem of securely communicating with the device is outsourced to the silicon vendor.
The private keys and certificates may be calculated by the OEM asynchronously to the manufacturing process, either done in batches in advance of actual manufacturing, or on demand when an IDevID is demanded.
Doing the processing in this way permits the key derivation system to be completely disconnected from any network, and requires placing very little trust in the system assembly factory.
Operational security such as often incorrectly presented fictionalized stories of a "mainframe" system to which only physical access is permitted begins to become realistic.
That trust has been replaced with a heightened trust placed in the silicon (integrated circuit) fabrication facility.

The downsides of this method to the OEM are: they must be supplied by a trusted silicon fabrication system, which must communicate the set of secrets seeds to the OEM in batches, and they OEM must store and care for these keys very carefully.
There are some operational advantages to keeping the secret seeds around in some form, as the same secret seed could be used for other things.
There are some significant downsides to keeping that secret seed around.

## Public Key infrastructure for IDevIDs

A three-tier PKI infrastructure is appropriate.
This entails having a root CA created with the key kept offline, and a number of intermediate CAs that have online keys that issue "day-to-day" certificates.

The root private key should be kept offline, quite probably in a Hardware Security Module if financially feasible.
If not, then it should be secret-split across seven to nine people, with a threshold of four to five people.
The split secrets should be kept in geographically diverse places if the manufacturer has operations in multiple places.
For examples of extreme measures, see {{kskceremony}}.
There is however a wide spectrum of needs, as exampled in {{rootkeyceremony}}.
The SAS70 audit standard is usually used as a basis for the Ceremony, see {{keyceremony2}}.

Ongoing access to the root-CA is important, but not as critical as access to the MASA key.

The root CA is then used to sign a number of intermediate entities.
If manufacturing occurs in multiple factories, then an intermediate CA for each factory is appropriate.
It is also reasonable to use different intermediate CAs for different product lines.
It may also be valuable to split IDevID certificates across intermediate CAs in a round-robin fashion for products with high volumes.

Cycling the intermediate CAs after a period of a few months or so is a quite reasonable strategy.
The intermediate CAs' private key may be destroyed after it signed some number of IDevIDs, and a new key generated.
The IDevID certificates have very long (ideally infinite) validity lifetimes for reasons that {{ieee802-1AR}} explains.
The intermediate CAs will have a private key, likely kept online, which is used to sign each generated IDevID. Once the IDevIDs are created, the private key is no longer needed and can either be destroyed, or taken offline.
In other CAs, the intermediate CA's private key (or another designated key) is often needed to sign OCSP {{?RFC6960}} or CRLS {{?RFC5280}}.
As the IDevID process does not in general support revocation, keeping such keys online is not necessary.
{EDIT NOTE: REVIEW of this NEEDED}

The intermediate CA certificate SHOULD be signed by the root-CA with indefinite (notAfter: 99991231) duration as well.

In all cases the product DN-serialNumber embedded in the certificate must be
unique across all products produced by the manufacturer.
This suggests some amount of structure to the product DN-serialNumber, such that
different intermediate CAs do not need to coordinate when issuing certificates.

# Privacy Considerations

many yet to be detailed

# Security Considerations

This entire document is a security considerations.

# IANA Considerations

This document makes no IANA requests.

# Acknowledgements

Hello.

# Changelog


--- back

